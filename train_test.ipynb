{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Utility operations\n",
    "from numpy import log as ln\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "# Saving objects\n",
    "import pickle\n",
    "\n",
    "# Optimization\n",
    "from functools import partial\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDCModels():\n",
    "    @classmethod\n",
    "    def save_model(self, model, filename):\n",
    "        with open(filename, 'wb') as outp:\n",
    "            pickle.dump(model, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(self, filename):\n",
    "        with open(filename, 'rb') as inp:\n",
    "            return pickle.load(inp)\n",
    "\n",
    "class ItemMemories():\n",
    "    @classmethod\n",
    "    def save_IM(self, im, filename):\n",
    "        with open(filename, 'wb') as outp:\n",
    "            pickle.dump(im, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_IM(self, filename):\n",
    "        with open(filename, 'rb') as inp:\n",
    "            return pickle.load(inp)\n",
    "\n",
    "class SparseHDC():\n",
    "    # Cyclic shifts the input hypervector arr by shift_count\n",
    "    @classmethod\n",
    "    def cyclic_shift(self, arr, shift_count=1):\n",
    "        return np.concatenate((arr[-shift_count:],arr[:-shift_count]))\n",
    "    \n",
    "    @classmethod\n",
    "    def dot(self, hv1, hv2):\n",
    "        return np.sum(np.logical_and(hv1, hv2))\n",
    "    \n",
    "    @classmethod\n",
    "    def disp(self, hv):\n",
    "        s = math.sqrt(len(hv))\n",
    "        if (s-int(s)):\n",
    "            return \"Must be square\"\n",
    "        \n",
    "        return np.array(hv).reshape(int(s),int(s))\n",
    "\n",
    "    # Generate a random sparse HV with dimension and sparsity\n",
    "    @classmethod\n",
    "    def generate_random_sparse_HV(self, dim = 10000, sparsity=0.3):\n",
    "        percent_sparsity = int(100*sparsity)\n",
    "        return np.vectorize(SparseHDC._generation_threshold)(np.random.randint(101,size=dim), percent_sparsity)\n",
    "    \n",
    "    # Generate count number of sparse HVs with dimension and sparsity\n",
    "    @classmethod\n",
    "    def generate_random_sparse_HVs(self, count=10, dim = 10000, sparsity=0.3):\n",
    "        return [SparseHDC.generate_random_sparse_HV(dim, sparsity) for i in range(0,count)]\n",
    "    \n",
    "    # Generate a sparse HV with exact sparsity\n",
    "    @classmethod\n",
    "    def generate_sparse_HV(self, dim=10000, sparsity=0.3):\n",
    "        hv = np.repeat(0,dim)\n",
    "        hv[random.sample(range(1,dim),int(sparsity*dim))]=1\n",
    "        return hv\n",
    "    \n",
    "    # Generate count number of sparse HV with dimension and exact sparsity\n",
    "    @classmethod\n",
    "    def generate_sparse_HVs(self, count=10, dim=10000, sparsity=0.3):\n",
    "        return [SparseHDC.generate_sparse_HV(dim, sparsity) for i in range(0,count)]\n",
    "    \n",
    "    # PRIVATE METHODS\n",
    "    \n",
    "    # Returns 1 if num < percent_sparsity where 0<=num<=100\n",
    "    @classmethod\n",
    "    def _generation_threshold(self, num, percent_sparsity = 30):\n",
    "        return 1 if num<percent_sparsity else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISOLET():\n",
    "    def __init__ (self, train_filepath = 'isolet1+2+3+4.csv', test_filepath = 'isolet5.csv'):\n",
    "        self.train = pd.read_csv(train_filepath, header=None)\n",
    "        self.train_X = self.train[[i for i in range(0,617)]]\n",
    "        self.train_y = self.train[617]\n",
    "        self.test = pd.read_csv(test_filepath, header=None)\n",
    "        self.test_X = self.test[[i for i in range(0,617)]]\n",
    "        self.test_y = self.test[617]\n",
    "        \n",
    "class ItemMemory():\n",
    "    def __init__(self, cim, base_hvs):\n",
    "        self.cim = cim\n",
    "        self.base_hvs = base_hvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsifying Method\n",
    "\n",
    "class ThresholdingSparsifier():\n",
    "    def __init__(self, percent_max_val=0.3, max_val=617):\n",
    "        self.percent_max_val = percent_max_val\n",
    "        self.max_val = max_val\n",
    "    \n",
    "    def sparsify(self, hv):\n",
    "        return np.array((hv>self.threshold())).astype(np.int)\n",
    "    \n",
    "    def threshold(self):\n",
    "        return int(self.percent_max_val*self.max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoloGNEncoder():\n",
    "    def __init__(self, M, cim, sparsifier, feature_count=617, shifts=None):\n",
    "        self.M = M\n",
    "        self.qlevels = self.quantization_levels(M)\n",
    "        self.cim = cim.generate(self.qlevels)\n",
    "        self.sparsifier = sparsifier\n",
    "        self.shifts = random.sample(range(0,feature_count),feature_count) if shifts is None else shifts\n",
    "        \n",
    "    def encode(self, features, return_accumulated=False):\n",
    "        # Quantize\n",
    "        quantized =  (map(self.get_level_hv, features))\n",
    "        # Get the shifted versions\n",
    "        shifted = pd.Series(map(SparseHDC.cyclic_shift, quantized, self.shifts))\n",
    "        # Sum up the shifted versions\n",
    "        acc = np.sum(shifted)\n",
    "        # Sparsify\n",
    "        sparse = self.sparsifier.sparsify(acc)\n",
    "        return acc if return_accumulated else sparse\n",
    "        \n",
    "\n",
    "    def quantization_levels(self, M, min_val=-1, max_val=1, precision=5):\n",
    "        step = (max_val - min_val) / (M-1)\n",
    "        qlevels = list(np.arange(min_val, max_val+(0.1*step), step).round(precision))\n",
    "        return qlevels\n",
    "\n",
    "    def get_level_hv(self, value, index=False):\n",
    "        closest_value = min(self.qlevels, key=lambda x:abs(x-value))\n",
    "        return self.cim[closest_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END-TO-END\n",
    "\n",
    "class HDC_Classifier():\n",
    "    def __init__(self, encoder, ACC_THR = 125, training_data=ISOLET()):\n",
    "        self.encoder = encoder\n",
    "        self.data = training_data\n",
    "        self.class_hvs = {}\n",
    "        self.training_encoded = {}\n",
    "        self.test_encoded = None\n",
    "        self.ACC_THR = ACC_THR\n",
    "\n",
    "    def train(self, save_encodes=True):      \n",
    "        # Group rows by class\n",
    "        classes = self.train_y().unique()\n",
    "        class_rows = {}\n",
    "        class_hvs = {}\n",
    "        \n",
    "    # Segregate the rows into their corresponding classes\n",
    "        # Get the indexes of the rows of different classes\n",
    "        class_indexes = {}\n",
    "        for class_ in classes:\n",
    "            class_indexes[class_] = list(self.train_y()[self.train_y()==class_].index)\n",
    "\n",
    "        # Segregated the rows\n",
    "        for class_ in classes:\n",
    "            class_rows[class_] = np.array(list(self.train_X().loc[class_indexes[class_]].itertuples(index=False, name=None)))\n",
    "\n",
    "        encoded = {}\n",
    "        for class_ in classes:\n",
    "            print(\"Encoding... {}% \".format(round(100*class_/classes[-1],2)))\n",
    "            encoded[class_] = pd.Series(map(self.encoder.encode, class_rows[class_]))\n",
    "        if save_encodes:\n",
    "            self.training_encoded = encoded\n",
    "        \n",
    "        accumulated = np.array([np.sum(encoded[class_]) for class_ in classes])\n",
    "        class_sparsifier = ThresholdingSparsifier(percent_max_val = self.ACC_THR/240, max_val=240)\n",
    "        thresholded = pd.Series(map(class_sparsifier.sparsify, accumulated))\n",
    "        thresholded.index = range(1,27)\n",
    "        \n",
    "        self.class_hvs = dict(thresholded)\n",
    "        \n",
    "        return \"Done\"\n",
    "    \n",
    "    def test(self):\n",
    "        encoded_test = pd.Series(map(self.encoder.encode, np.array(self.test_X())))\n",
    "        predictions = pd.Series(map(self.query, encoded_test))\n",
    "        return np.sum(predictions == self.test_y())/len(self.test_y())\n",
    "\n",
    "    # HELPER FUNCTIONS\n",
    "    def query(self, query_hv):\n",
    "        d = dict([[class_, SparseHDC.dot(class_hv, query_hv)] for class_,class_hv in self.class_hvs.items()])\n",
    "        return max(d, key=d.get)\n",
    "    \n",
    "    def train_X(self):\n",
    "        return self.data.train_X\n",
    "    \n",
    "    def train_y(self):\n",
    "        return self.data.train_y\n",
    "    \n",
    "    def test_X(self):\n",
    "        return self.data.test_X\n",
    "    \n",
    "    def test_y(self):\n",
    "        return self.data.test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEVELOPMENT\n",
    "\n",
    "### CONVERT NEXT THREE CELLS TO CODE AND RUN AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS ONCE\n",
    "\n",
    "isolet = ISOLET()\n",
    "\n",
    "# Rows in each class\n",
    "class_indexes = {}\n",
    "classes = range(1,27)\n",
    "for class_ in classes:\n",
    "    class_indexes[class_] = list(isolet.train_y[isolet.train_y==class_].index)\n",
    "\n",
    "# Rows for each class\n",
    "# class_rows[class_no][sample_no], class_no corresponds to A-Z but 1-26 instead\n",
    "class_rows = {}\n",
    "for class_ in classes:\n",
    "    class_rows[class_] = np.array(list(isolet.train_X.loc[class_indexes[class_]].itertuples(index=False, name=None)))\n",
    "    \n",
    "# 10 rows for each class\n",
    "test_class_rows = {}\n",
    "\n",
    "for class_, rows in class_rows.items():\n",
    "    test_class_rows[class_] = rows[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sparsity_vs_accumulation_threshold(encoded_training_data, sparsity, interval=[0,99]):\n",
    "    classes = list(encoded_training_data.keys())\n",
    "    dim = len(encoded_training_data[classes[0]][0])\n",
    "    \n",
    "    #Accumulate each class\n",
    "    class_accumulations = [np.sum(encoded_training_data[class_]) for class_ in classes]\n",
    "    \n",
    "    for accumulation in class_accumulations:\n",
    "        sparsities = []\n",
    "        for i in range(interval[0],interval[1]+1):\n",
    "            sp = ThresholdingSparsifier(percent_max_val=i/100, max_val=240)\n",
    "            sparsities.append(np.sum(sp.sparsify(accumulation))/dim)\n",
    "        plt.plot(range(interval[0],interval[1]+1), sparsities)\n",
    "        \n",
    "    plt.title(\"Sparsity vs Percent ACC THR (Component Sparsity ~{})\".format(sparsity))\n",
    "    plt.xlabel(\"threshold (% of component count)\")\n",
    "    plt.ylabel(\"sparsity\")\n",
    "    \n",
    "def plot_encoding_sparsity_jitter(encoded_training_data, target_sparsity, ENC_THR=\"x\"):\n",
    "    classes = list(encoded_training_data.keys())\n",
    "    dim = len(encoded_training_data[classes[0]][0])\n",
    "    no_of_ones = np.array([])\n",
    "\n",
    "    for class_ in classes:\n",
    "        no_of_ones = np.append(no_of_ones, np.vectorize(np.sum)(encoded_training_data[class_]))\n",
    "        \n",
    "    sparsities = no_of_ones\n",
    "    print(\"Mean sparsity: {}\".format(np.average(sparsities)))\n",
    "    sns.boxplot(sparsities)\n",
    "    plt.title(\"Sparsity of Encoded Training Samples at ENC_THR={}\".format(ENC_THR))\n",
    "    plt.xlabel('sample no.')\n",
    "    plt.ylabel('sparsity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=1000\n",
    "sp=0.05\n",
    "ENC_THR=38\n",
    "ACC_THR=109\n",
    "M=2\n",
    "\n",
    "hologn = HoloGNEncoder(dim=dim, sparsity=sp, M=M, ENC_THR=ENC_THR)\n",
    "classifier = HDC_Classifier(hologn, ACC_THR=ACC_THR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding... 3.85% \n",
      "Encoding... 7.69% \n",
      "Encoding... 11.54% \n",
      "Encoding... 15.38% \n",
      "Encoding... 19.23% \n",
      "Encoding... 23.08% \n",
      "Encoding... 26.92% \n",
      "Encoding... 30.77% \n",
      "Encoding... 34.62% \n",
      "Encoding... 38.46% \n",
      "Encoding... 42.31% \n",
      "Encoding... 46.15% \n",
      "Encoding... 50.0% \n",
      "Encoding... 53.85% \n",
      "Encoding... 57.69% \n",
      "Encoding... 61.54% \n",
      "Encoding... 65.38% \n",
      "Encoding... 69.23% \n",
      "Encoding... 73.08% \n",
      "Encoding... 76.92% \n",
      "Encoding... 80.77% \n",
      "Encoding... 84.62% \n",
      "Encoding... 88.46% \n",
      "Encoding... 92.31% \n",
      "Encoding... 96.15% \n",
      "Encoding... 100.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985888389993585"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 3013.769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ones = []\n",
    "for c,hv in classifier.class_hvs.items():\n",
    "    ones.append(np.sum(hv))\n",
    "print(\"Mean {}\".format(np.average(ones)))\n",
    "sns.boxplot(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sparsity: 3016.198781660789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_encoding_sparsity_jitter(classifier.training_encoded, target_sparsity=sp, ENC_THR=ENC_THR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
