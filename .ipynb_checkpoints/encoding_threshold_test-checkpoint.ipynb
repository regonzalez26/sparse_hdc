{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Utility operations\n",
    "from numpy import log as ln\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "# Saving objects\n",
    "import pickle\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDCModels():\n",
    "    @classmethod\n",
    "    def save_model(self, model, filename):\n",
    "        with open(filename, 'wb') as outp:\n",
    "            pickle.dump(model, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(self, filename):\n",
    "        with open(filename, 'rb') as inp:\n",
    "            return pickle.load(inp)\n",
    "\n",
    "class ItemMemories():\n",
    "    @classmethod\n",
    "    def save_IM(self, im, filename):\n",
    "        with open(filename, 'wb') as outp:\n",
    "            pickle.dump(im, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_IM(self, filename):\n",
    "        with open(filename, 'rb') as inp:\n",
    "            return pickle.load(inp)\n",
    "\n",
    "class SparseHDC():\n",
    "    # Cyclic shifts the input hypervector arr by shift_count\n",
    "    @classmethod\n",
    "    def cyclic_shift(self, arr, shift_count=1):\n",
    "        return np.concatenate((arr[-shift_count:],arr[:-shift_count]))\n",
    "    \n",
    "    @classmethod\n",
    "    def dot(self, hv1, hv2):\n",
    "        return np.sum(np.logical_and(hv1, hv2))\n",
    "    \n",
    "    @classmethod\n",
    "    def disp(self, hv):\n",
    "        s = math.sqrt(len(hv))\n",
    "        if (s-int(s)):\n",
    "            return \"Must be square\"\n",
    "        \n",
    "        return np.array(hv).reshape(int(s),int(s))\n",
    "\n",
    "    # Generate a random sparse HV with dimension and sparsity\n",
    "    @classmethod\n",
    "    def generate_random_sparse_HV(self, dim = 10000, sparsity=0.3):\n",
    "        percent_sparsity = int(100*sparsity)\n",
    "        return np.vectorize(SparseHDC._generation_threshold)(np.random.randint(101,size=dim), percent_sparsity)\n",
    "    \n",
    "    # Generate count number of sparse HVs with dimension and sparsity\n",
    "    @classmethod\n",
    "    def generate_random_sparse_HVs(self, count=10, dim = 10000, sparsity=0.3):\n",
    "        return [SparseHDC.generate_random_sparse_HV(dim, sparsity) for i in range(0,count)]\n",
    "    \n",
    "    # Generate a sparse HV with exact sparsity\n",
    "    @classmethod\n",
    "    def generate_sparse_HV(self, dim=10000, sparsity=0.3):\n",
    "        hv = np.repeat(0,dim)\n",
    "        hv[random.sample(range(1,dim),int(sparsity*dim))]=1\n",
    "        return hv\n",
    "    \n",
    "    # Generate count number of sparse HV with dimension and exact sparsity\n",
    "    @classmethod\n",
    "    def generate_sparse_HVs(self, count=10, dim=10000, sparsity=0.3):\n",
    "        return [SparseHDC.generate_sparse_HV(dim, sparsity) for i in range(0,count)]\n",
    "    \n",
    "    # PRIVATE METHODS\n",
    "    \n",
    "    # Returns 1 if num < percent_sparsity where 0<=num<=100\n",
    "    @classmethod\n",
    "    def _generation_threshold(self, num, percent_sparsity = 30):\n",
    "        return 1 if num<percent_sparsity else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISOLET():\n",
    "    def __init__ (self, train_filepath = 'isolet1+2+3+4.csv', test_filepath = 'isolet5.csv'):\n",
    "        self.train = pd.read_csv(train_filepath, header=None)\n",
    "        self.train_X = self.train[[i for i in range(0,617)]]\n",
    "        self.train_y = self.train[617]\n",
    "        self.test = pd.read_csv(test_filepath, header=None)\n",
    "        self.test_X = self.test[[i for i in range(0,617)]]\n",
    "        self.test_y = self.test[617]\n",
    "\n",
    "class ItemMemory():\n",
    "    def __init__(self, cim, base_hvs):\n",
    "        self.cim = cim\n",
    "        self.base_hvs = base_hvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Item Memory Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCIM():\n",
    "    def __init__(self, sparsity=0.3, dim=10000, seed=None):\n",
    "        self.sparsity = sparsity\n",
    "        self.dim = dim\n",
    "        self.seed = seed\n",
    "    \n",
    "    def modify_specs(self, sparsity=None, dim=None):\n",
    "        self.sparsity = sparsity if sparsity else self.sparsity\n",
    "        self.dim = dim if dim else self.dim\n",
    "\n",
    "    def generate(self, keys):\n",
    "        if self.seed is None:\n",
    "            seed = SparseHDC.generate_sparse_HV(sparsity=self.sparsity, dim=self.dim)\n",
    "        else:\n",
    "            seed = self.seed\n",
    "        \n",
    "        tracker = pd.Series(np.copy(seed))\n",
    "        bit_step = int(np.sum(seed)/(len(keys)-1))\n",
    "        hvs = [seed]\n",
    "\n",
    "        for i in range(1,len(keys)):\n",
    "            next_hv = np.copy(hvs[i-1])\n",
    "\n",
    "            # TURN OFF K bits\n",
    "            turnoff_index = random.sample(list(tracker[tracker==1].index), bit_step)\n",
    "            tracker[turnoff_index]=-1 #Update to cannot be touched\n",
    "            next_hv[turnoff_index]=0 #Turn them off from previous hv\n",
    "\n",
    "            # TURN ON K bits\n",
    "            turnon_index = random.sample(list(tracker[tracker==0].index), bit_step)\n",
    "            tracker[turnon_index]=-1 #Update to cannot be touched\n",
    "            next_hv[turnon_index]=1 #Turn them on\n",
    "\n",
    "            hvs.append(next_hv)\n",
    "            \n",
    "        return dict(zip(keys,hvs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binding Method\n",
    "    \n",
    "class MBitSignatureBinder(): #(Imani et.al. 2019)\n",
    "    def __init__(self, base_hv_count=617, level_hv_count=10, range_multiplier=10):\n",
    "        self.base_shifts = random.sample(range(0,base_hv_count*range_multiplier), base_hv_count)\n",
    "        self.level_shifts = random.sample(range(0,level_hv_count*range_multiplier), level_hv_count)\n",
    "        \n",
    "    def bind(self, base, base_no, level, level_no):\n",
    "        return ((SparseHDC.cyclic_shift(base, self.base_shifts[base_no]) + SparseHDC.cyclic_shift(level, self.level_shifts[level_no]))>1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsifying Method\n",
    "\n",
    "class ThresholdingSparsifier():\n",
    "    def __init__(self, percent_max_val=0.3, max_val=617):\n",
    "        self.percent_max_val = percent_max_val\n",
    "        self.max_val = max_val\n",
    "    \n",
    "    def sparsify(self, hv):\n",
    "        return np.array((hv>self.threshold())).astype(np.int)\n",
    "    \n",
    "    def threshold(self):\n",
    "        return int(self.percent_max_val*self.max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING ALGORITHMS\n",
    "\n",
    "class Sparse_FeatureEncoder():\n",
    "    def __init__(self, cim_generator, binder, sparsifier, sparsity=0.3, feature_count=617, qlevel_count=10, dim=10000):\n",
    "        self.cim = cim_generator\n",
    "        self.binder = binder\n",
    "        self.sparsifier = sparsifier\n",
    "        self.feature_count = feature_count\n",
    "        self.qlevel_count = qlevel_count\n",
    "        self.sparsity = sparsity\n",
    "        self.dim = dim    \n",
    "        self.base_hvs = SparseHDC.generate_sparse_HVs(count=feature_count, sparsity=sparsity, dim=dim)\n",
    "        \n",
    "        #Setup functions\n",
    "        self.qlevels = self.quantization_levels()\n",
    "        self.setup_CIM()\n",
    "    \n",
    "    def change_sparsity(sparsity=0.3):\n",
    "        pass\n",
    "\n",
    "    def encode(self, features, return_accumulated=False):\n",
    "        if len(features)!=self.feature_count:\n",
    "            return \"Invalid number of features\"\n",
    "\n",
    "        #Quantize\n",
    "        quantized = np.vectorize(self.quantize)(features)\n",
    "        level_nos = [self.qlevels.index(q) for q in quantized]\n",
    "        \n",
    "        #Map to CIM\n",
    "        mapped_to_hvs = [self.cim[v] for v in quantized]\n",
    "        \n",
    "         # Bind and Accumulate (Summation of Base*Level)\n",
    "        accumulated_hv = np.repeat(0,self.dim)\n",
    "        for i in range(0,self.feature_count):\n",
    "             accumulated_hv += self.binder.bind(\n",
    "                                    base=self.base_hvs[i],\n",
    "                                    base_no=i, \n",
    "                                    level=mapped_to_hvs[i],\n",
    "                                    level_no=level_nos[i]\n",
    "                                )\n",
    "        \n",
    "        thresholded_hv = self.sparsifier.sparsify(accumulated_hv)\n",
    "\n",
    "        return accumulated_hv if return_accumulated else thresholded_hv\n",
    "    \n",
    "    # ENCAPSULATED DEPENDENCY METHODS\n",
    "\n",
    "    def setup_CIM(self):\n",
    "        self.cim = self.cim.generate(self.qlevels)\n",
    "\n",
    "    # ENCODING HELPERS\n",
    "    def quantization_levels(self, min_val=-1, max_val=1, precision=5):\n",
    "        step = (max_val - min_val) / (self.qlevel_count-1)\n",
    "        return list(np.arange(min_val, max_val+(0.1*step), step).round(precision))\n",
    "            \n",
    "    def quantize(self, value):\n",
    "        return min(self.qlevels, key=lambda x:abs(x-value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA VARIABLES\n",
    "\n",
    "isolet = ISOLET()\n",
    "\n",
    "# Rows in each class\n",
    "class_indexes = {}\n",
    "classes = range(1,27)\n",
    "for class_ in classes:\n",
    "    class_indexes[class_] = list(isolet.train_y[isolet.train_y==class_].index)\n",
    "\n",
    "# Rows for each class\n",
    "# class_rows[class_no][sample_no], class_no corresponds to A-Z but 1-26 instead\n",
    "class_rows = {}\n",
    "for class_ in classes:\n",
    "    class_rows[class_] = np.array(list(isolet.train_X.loc[class_indexes[class_]].itertuples(index=False, name=None)))\n",
    "\n",
    "# 10 rows for each class\n",
    "test_class_rows = {}\n",
    "\n",
    "for class_, rows in class_rows.items():\n",
    "    test_class_rows[class_] = rows[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FUNCTIONS\n",
    "\n",
    "def setup_feature_encoder(dim=10000, sparsity=0.3, percent_max_val=0.45, M=10,\n",
    "                          range_multiplier=1, load_IM=None, seed=None):\n",
    "    cim_generator = LinearCIM(sparsity=sparsity, dim=dim, seed=seed)\n",
    "    binder = MBitSignatureBinder(level_hv_count=M, range_multiplier=range_multiplier)\n",
    "    sparsifier = ThresholdingSparsifier(percent_max_val=percent_max_val)\n",
    "    encoder = Sparse_FeatureEncoder(\n",
    "                cim_generator = cim_generator,\n",
    "                binder = binder,\n",
    "                sparsifier = sparsifier,\n",
    "                sparsity = sparsity,\n",
    "                dim = dim,\n",
    "                qlevel_count = M\n",
    "            )\n",
    "    if load_IM:\n",
    "        im = ItemMemories.load_IM(load_IM)\n",
    "        encoder.cim = im.cim\n",
    "        encoder.base_hvs = im.base_hvs\n",
    "    return encoder\n",
    "    \n",
    "def plot_sparsity_vs_encoding_threshold(encoder, test_class_rows, interval=[0,100]):\n",
    "    for class_ in test_class_rows.keys():\n",
    "        for row in test_class_rows[class_]:\n",
    "            sample_encode = encoder.encode(row, return_accumulated = True)\n",
    "\n",
    "            sparsity_values = []\n",
    "            for i in range(interval[0], interval[1]+1):\n",
    "                sp = ThresholdingSparsifier(percent_max_val=i/100)\n",
    "                sparsity_values.append(np.sum(sp.sparsify(sample_encode))/10000)\n",
    "\n",
    "            plt.plot(range(interval[0], interval[1]+1), sparsity_values)\n",
    "\n",
    "    plt.title(\"Sparsity vs Percent Threshold (Component Sparsity ~ {})\".format(encoder.sparsity))\n",
    "    plt.ylabel(\"sparsity\")\n",
    "    plt.xlabel(\"threshold (% of component count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN TESTS HERE\n",
    "### Please run the setup cells before testing as well as the library class (all the previous cells)\n",
    "## For 617 accumulated Sparse HVs, what must be the threshold value to yield the desired sparsity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'im/sp-0.05/im_sp-0.05_m28.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-21facf929224>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m encoder = setup_feature_encoder(dim=10000, sparsity=0.05,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 M=m, load_IM='im/sp-0.05/im_sp-0.05_m{}.pkl'.format(m))\n\u001b[0;32m      4\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_sparsity_vs_encoding_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_class_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_class_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-d5e94f41e381>\u001b[0m in \u001b[0;36msetup_feature_encoder\u001b[1;34m(dim, sparsity, percent_max_val, M, range_multiplier, load_IM, seed)\u001b[0m\n\u001b[0;32m     15\u001b[0m             )\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mload_IM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mItemMemories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_IM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_IM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_hvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_hvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-274d74973771>\u001b[0m in \u001b[0;36mload_IM\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_IM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'im/sp-0.05/im_sp-0.05_m28.pkl'"
     ]
    }
   ],
   "source": [
    "m = 28\n",
    "encoder = setup_feature_encoder(dim=10000, sparsity=0.05,\n",
    "                                M=m, load_IM='im/sp-0.05/im_sp-0.05_m{}.pkl'.format(m))\n",
    "figure(figsize=(4,3), dpi=200)\n",
    "plot_sparsity_vs_encoding_threshold(encoder=encoder, test_class_rows=test_class_rows, interval=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of ones: 1438.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_of_ones = []\n",
    "encoder.sparsifier.percent_max_val = 3/617\n",
    "for class_ in classes:\n",
    "    for row in test_class_rows[class_]:\n",
    "        no_of_ones.append( np.sum(encoder.encode(row)) )\n",
    "\n",
    "print(\"Mean number of ones: {}\".format(np.average(np.array(no_of_ones))))\n",
    "sns.boxplot(x=no_of_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
